{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASYNCIO Theory\n",
    "\n",
    "- <span style='font-size:16px;'> coroutines defined with operator async </span> \n",
    "```python \n",
    "async def foo():\n",
    "    print('hello')\n",
    "    await asyncio.sleep(1)\n",
    "    print('world')\n",
    "asyncio.run(foo()) \n",
    "await foo() # in jupyter (because jupyter runs it's own event_loop, which causes problems, moreover loops cannot be nested)\n",
    "``` \n",
    "- <span style='font-size:16px;'> await passes management to event_loop </span>\n",
    "- <span style='font-size:16px;'> nested coroutines </span>\n",
    "\n",
    "```python \n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def say_after(delay, what):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(what)\n",
    "\n",
    "async def main():\n",
    "    print(f\"started at {time.strftime('%X')}\")\n",
    "\n",
    "    await say_after(1, 'hello')\n",
    "    await say_after(2, 'world')\n",
    "\n",
    "    print(f\"finished at {time.strftime('%X')}\")\n",
    "\n",
    "asyncio.run(main()) # in jupyter change to await \n",
    "```\n",
    "- <span style='font-size:16px;'> create_task function that allows run coroutines concurentently (as i understand simplyfied syntax) </span>\n",
    "\n",
    "```python \n",
    "async def main():\n",
    "    task1 = asyncio.create_task(\n",
    "        say_after(1, 'hello'))\n",
    "\n",
    "    task2 = asyncio.create_task(\n",
    "        say_after(2, 'world'))\n",
    "\n",
    "    print(f\"started at {time.strftime('%X')}\")\n",
    "\n",
    "    # Wait until both tasks are completed (should take\n",
    "    # around 2 seconds.)\n",
    "    await task1\n",
    "    await task2\n",
    "\n",
    "    print(f\"finished at {time.strftime('%X')}\")\n",
    "await main() # in jupyter\n",
    "```\n",
    "- <span style='font-size:16px'> awaitable object - object that can be used in await expression </span>\n",
    "    - coroutines\n",
    "    - tasks \n",
    "    - futures\n",
    "\n",
    "### Coroutines:\n",
    "\n",
    "---\n",
    "**Object that has async operator and also obkecj returned by another coroutine**\n",
    "\n",
    "---\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def nested():\n",
    "    return 42\n",
    "\n",
    "async def main():\n",
    "    # Nothing happens if we just call \"nested()\".\n",
    "    # A coroutine object is created but not awaited,\n",
    "    # so it *won't run at all*.\n",
    "    nested()\n",
    "\n",
    "    # Let's do it differently now and await it:\n",
    "    print(await nested())  # will print \"42\".\n",
    "\n",
    "asyncio.run(main())\n",
    "```\n",
    "### Tasks \n",
    "\n",
    "---\n",
    "**Tasks are used to schedule coroutines concurrently.**\n",
    "\n",
    "---\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def nested():\n",
    "    return 42\n",
    "\n",
    "async def main():\n",
    "    # Schedule nested() to run soon concurrently\n",
    "    # with \"main()\".\n",
    "    task = asyncio.create_task(nested())\n",
    "\n",
    "    # \"task\" can now be used to cancel \"nested()\", or\n",
    "    # can simply be awaited to wait until it is complete:\n",
    "    await task\n",
    "\n",
    "asyncio.run(main())\n",
    "```\n",
    "NOTE: task behaves differently - return do tnot printed, it probabaly has higher api\n",
    "\n",
    "### Futures\n",
    "\n",
    "---\n",
    "**A Future is a special low-level awaitable object that represents an eventual result of an asynchronous operation.** <br>\n",
    "When a Future object is awaited it means that the coroutine will wait until the Future is resolved in some other place. <br>\n",
    "Future objects in asyncio are needed to allow callback-based code to be used with async/await.\n",
    "\n",
    "**Normally there is no need to create Future objects at the application level code.**\n",
    "\n",
    "---\n",
    "\n",
    "```python \n",
    "async def main():\n",
    "    await function_that_returns_a_future_object()\n",
    "\n",
    "    # this is also valid:\n",
    "    await asyncio.gather(\n",
    "        function_that_returns_a_future_object(),\n",
    "        some_python_coroutine()\n",
    "    )\n",
    "\n",
    "```\n",
    "NOTE: we do not really need this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## small example \n",
    "\n",
    "async def foo():\n",
    "    await asyncio.sleep(1)\n",
    "    return 4\n",
    "\n",
    "async def boo():\n",
    "    await asyncio.sleep(2)\n",
    "    return 5\n",
    "\n",
    "async def main():\n",
    "    task1 = asyncio.create_task(foo())\n",
    "    task2 = asyncio.create_task(boo())\n",
    "    \n",
    "    return await asyncio.gather(*[task1, task2])\n",
    "\n",
    "f = await main()\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "---\n",
    "Choose appropriate proxy for requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd \n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "import time\n",
    "import operator as op\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline: \n",
    "- list of proxies. \n",
    "- function my_ip call api to check ip adress. \n",
    "- iterate over all possible proxies to find availble and fast.\n",
    "- sort by callback time, choose 10-15 fastest, randomly pick up one and put into proxy settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProxies():\n",
    "    '''\n",
    "    Function returns pandas dataframe of available proxies from site: https://free-proxy-list.net/\n",
    "    NOTE: probabaly it's not the best place to get proxies, therefore TODO: add other resources.\n",
    "    '''\n",
    "    r = requests.get('https://free-proxy-list.net/') #, headers=header\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    t = soup.find_all('table', {'id':'proxylisttable'})\n",
    "    a = pd.read_html(str(t[0]), flavor='bs4', skiprows=0)[0]\n",
    "    a = a.dropna()\n",
    "    a['Port'] = a['Port'].astype(int)\n",
    "    a[['IP Address', 'Port']] = a[['IP Address', 'Port']].astype(str)\n",
    "    a['target'] = a[['IP Address', 'Port']].astype(str).apply(lambda x: ':'.join([str(x[0]), str(x[1])]), axis=1)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = getProxies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IP Address</th>\n",
       "      <th>Port</th>\n",
       "      <th>Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Anonymity</th>\n",
       "      <th>Google</th>\n",
       "      <th>Https</th>\n",
       "      <th>Last Checked</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.78.80.194</td>\n",
       "      <td>33442</td>\n",
       "      <td>ID</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1 minute ago</td>\n",
       "      <td>103.78.80.194:33442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115.87.110.143</td>\n",
       "      <td>8118</td>\n",
       "      <td>TH</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 minute ago</td>\n",
       "      <td>115.87.110.143:8118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.167.255.227</td>\n",
       "      <td>8080</td>\n",
       "      <td>RU</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1 minute ago</td>\n",
       "      <td>5.167.255.227:8080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139.5.71.46</td>\n",
       "      <td>23500</td>\n",
       "      <td>NP</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 minute ago</td>\n",
       "      <td>139.5.71.46:23500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.94.121.27</td>\n",
       "      <td>60109</td>\n",
       "      <td>ID</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>elite proxy</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1 minute ago</td>\n",
       "      <td>103.94.121.27:60109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IP Address   Port Code             Country    Anonymity Google Https  \\\n",
       "0   103.78.80.194  33442   ID           Indonesia  elite proxy     no    no   \n",
       "1  115.87.110.143   8118   TH            Thailand    anonymous     no   yes   \n",
       "2   5.167.255.227   8080   RU  Russian Federation  elite proxy     no    no   \n",
       "3     139.5.71.46  23500   NP               Nepal  elite proxy     no   yes   \n",
       "4   103.94.121.27  60109   ID           Indonesia  elite proxy     no    no   \n",
       "\n",
       "   Last Checked               target  \n",
       "0  1 minute ago  103.78.80.194:33442  \n",
       "1  1 minute ago  115.87.110.143:8118  \n",
       "2  1 minute ago   5.167.255.227:8080  \n",
       "3  1 minute ago    139.5.71.46:23500  \n",
       "4  1 minute ago  103.94.121.27:60109  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIOHTTP version\n",
    "NOTE: do not handle with https"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "execution time 6.133014917373657\n"
     ]
    }
   ],
   "source": [
    "async def fetch(url, session, proxy=None, timeout=None):\n",
    "    '''Function designed to make requests in aiohttp.ClientSession() way. \n",
    "    All function is substitution of requests.get() function. It's more native way to work with aio. \n",
    "    Function returns response itself and time response was waited. \n",
    "    '''\n",
    "    start = time.process_time() \n",
    "    async with session.get(url, proxy=proxy, timeout=timeout) as response:\n",
    "        res = await response.read() # pass event_loop\n",
    "        return res.decode('utf-8'), time.process_time() - start\n",
    "\n",
    "\n",
    "async def my_ip(proxies=None, timeout=None):\n",
    "    '''\n",
    "    Function checks availability of proxy server asking for ip. \n",
    "    Function supposed to be more protected due to the reason it \n",
    "    uses double context manager 'with' - in session and response manner. \n",
    "    '''\n",
    "    async with ClientSession() as session:\n",
    "        await asyncio.sleep(1)\n",
    "        try:\n",
    "            res = await fetch('http://myip.ru/index_small.php', session=session, proxy=proxies, timeout=timeout) # requests via await to pass to event_loop\n",
    "            soup =  BeautifulSoup(res[0])\n",
    "            return soup.find('table', {'class':'network-info'}).find_all('tr')[1].find('td').get_text(), res[1]\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "start = time.time() \n",
    "tasks = [] # list of futures \n",
    "for i in p['target'][:10]: \n",
    "    #proxies = {'http':i, 'https':i} # aiohttp do not handle https\n",
    "    proxies = f'http://{i}'\n",
    "    task = asyncio.create_task(my_ip(proxies, 5)) # create_task - is high level future. Low level futeres do not recomended to use. \n",
    "    tasks.append(task) # list of promises\n",
    "async def main():\n",
    "    return await asyncio.gather(*tasks)\n",
    "f = await main()\n",
    "# f = asincio.run(main()) # console version, due to the reason, jupyter already run own event_loop\n",
    "print(f'execution time {time.time()-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def my_ip(proxies=None, timeout=None):\n",
    "    await asyncio.sleep(1)\n",
    "    try:\n",
    "        soup =  BeautifulSoup(requests.get('http://myip.ru/index_small.php', proxies=proxies, timeout=timeout).text)\n",
    "        return soup.find('table', {'class':'network-info'}).find_all('tr')[1].find('td').get_text()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return None\n",
    "async def main():\n",
    "    return await my_ip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPConnectionPool(host='103.78.80.194', port=33442): Read timed out. (read timeout=5)\n",
      "HTTPConnectionPool(host='115.87.110.143', port=8118): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f256405a3d0>, 'Connection to 115.87.110.143 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='5.167.255.227', port=8080): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f256405b510>, 'Connection to 5.167.255.227 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='139.5.71.46', port=23500): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f256405c450>, 'Connection to 139.5.71.46 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='103.94.121.27', port=60109): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f256405b510>, 'Connection to 103.94.121.27 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='185.51.36.152', port=41258): Read timed out. (read timeout=5)\n",
      "HTTPConnectionPool(host='109.74.132.190', port=55838): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f256405cdd0>, 'Connection to 109.74.132.190 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='103.111.54.26', port=49781): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f256405d790>, 'Connection to 103.111.54.26 timed out. (connect timeout=5)'))\n",
      "execution time 49.8400239944458\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tasks = []\n",
    "for i in p['target'][:10]: \n",
    "    proxies = {'http':i, 'https':i}\n",
    "    task = asyncio.create_task(my_ip(proxies, 5))\n",
    "    tasks.append(task)\n",
    "async def main():\n",
    "    return await asyncio.gather(*tasks)\n",
    "f = await main()\n",
    "print(f'execution time {time.time()-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPConnectionPool(host='103.78.80.194', port=33442): Read timed out. (read timeout=5)\n",
      "HTTPConnectionPool(host='115.87.110.143', port=8118): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f2564055250>, 'Connection to 115.87.110.143 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='5.167.255.227', port=8080): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f256405bf10>, 'Connection to 5.167.255.227 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='139.5.71.46', port=23500): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f2564055250>, 'Connection to 139.5.71.46 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='79.111.13.155', port=50625): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f256405b110>, 'Connection to 79.111.13.155 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='185.51.36.152', port=41258): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f2563fe0b50>, 'Connection to 185.51.36.152 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='109.74.132.190', port=55838): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f25640565d0>, 'Connection to 109.74.132.190 timed out. (connect timeout=5)'))\n",
      "HTTPConnectionPool(host='103.111.54.26', port=49781): Max retries exceeded with url: http://myip.ru/index_small.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f256405e590>, 'Connection to 103.111.54.26 timed out. (connect timeout=5)'))\n",
      "execution time 57.922077655792236\n"
     ]
    }
   ],
   "source": [
    "def my_ip_sync(proxies=None, timeout=None):\n",
    "    time.sleep(1) # to be honest - asyncio.sleep(1)\n",
    "    try:\n",
    "        soup =  BeautifulSoup(requests.get('http://myip.ru/index_small.php', proxies=proxies, timeout=timeout).text)\n",
    "        return soup.find('table', {'class':'network-info'}).find_all('tr')[1].find('td').get_text()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "start = time.time()\n",
    "f2 = []  \n",
    "for i in p['target'][:10]:\n",
    "    proxies = {'http':i, 'https':i}\n",
    "    f2.append(my_ip_sync(proxies, 5))\n",
    "print(f'execution time {time.time() - start}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
